import streamlit as st

st.title("How to use Log2enc?")

st.write("""
        The first step is to upload an event log (it should contain a "label" attribute). The maximum allowed size is 15 MB, the only extension accepted is *.xes*.
        In case you do not have any event logs, you can download one of ours. You can find them at the end of Homepage. \n
        After uploading an event log, a sidebar appears on the left side of the screen. In the sidebar you can find different configuration options:
        1. **Select the dimension**: this option allows you to choose the size of the resulting vectors. 
                                The minimum selectable size is 2, while the maximum size is 256.
                                Note that the minimum and maximum size for some algorithms is not the same. 
                                For BoostNE the minimum size is 17, the maximum size is 255. 
                                For GLEE, GraRep, Laplacian Eigenmaps and NetMF the maximum size is 16, while for HOPE the largest size reaches 32.
        2. **Select the aggregation for word embedding**: here you can choose the type of embedding between *Average* or *Max*.\n
            If *Average* is chosen, a trace is represented as the sum of the vectors of the activities that compose it, 
            divided by the number of activities.
            If *Max* is chosen, a track is represented with the maximum value of the activities that compose it.
        3. **Select the aggregation for graph embedding**: here you can choose whether to encode *Nodes* or *Edges*. 
            If you choose to encode the *Nodes* you will need to specify whether to use *Max* or *Average* aggregation.
            The encoding of an edge is generated by aggregating the two node that use this edge. 
            If you choose to encode the *Edges* you will need to specify between *Average*, *Hadamard*, *Weightedl1*, *Weightedl2*.
            This aggregation describe how the nodes are aggregated. Then it is necessary to specify how to aggregate the edges.
                                
        4. **Submit your email address**: The last step requires you to enter an email address. 
                                After three uses you will have to wait only 5 minutes to be able to upload an event log again.
            \n
        Press the Confirm button and wait for the processing to complete. Take it easy, it can take a few minutes. In the meantime you can do something else: as soon as the processing is finished you will receive an email notification!
        """)

st.markdown("""---""")

st.header("The encoding methods")
st.write("""We compared different encoding methods representative of both traditional PM methods, 
            such a trace replay and alignment, and methods producing highly informative but low-dimensional 
            vectors such as graph embeddings and word embeddings.""")

st.subheader("Trace encoding")
st.write("""
        Most PM quality measures are based on conformance checking methods, which aim at comparing a process execution to a process model. 
        The measures produced by conformance checking techniques can be interpreted as features. 
        More specifically, we exploited conformance checking algorithms to encode traces:
        1. Alignment
        2. Token Replay
        3. Log Skeleton
    """)
st.subheader("Word embeddings")
st.write("""
        Word embeddings are grounded in information retrieval and natural language processing. 
        Neural network algorithms are exploited to create highly informative but low-dimensional vectors 
        modeling the context in which words of a corpus are inserted.
        1. Count2Vec
        2. Doc2Vec
        3. HashVectorizer
        4. Glove
        5. One Hot encoding
        6. TFIDF Vectorizer
        7. Word2Vec
    """)
st.subheader("Graph embedding")
st.write("""
        Graph embeddings emerged from the necessity of modeling more complex relations, 
        such as entity links and long-term relations. Graphs are suitable for this task due to their data representation format, 
        enabling exploration of nodes and edges. 
        1. BoostNE
        2. Deep Walk
        3. Diff2Vec
        4. Glee
        5. Graph Wave
        6. Grarep
        7. Hope
        8. Laplacian Eigen Maps
        9. NetMF
        10. NMFadmn
        11. Node2Vec
        12. Node sketch
        13. Walklets
        14. Role2Vec
    """)

st.markdown("""---""")

st.header("The metrics")
st.write("""We computed our measures using the [ECoL](https://github.com/lpfgarcia/ECoL) (Extended Complexity Library) R package. 
                This implementation characterize the complexity of classification and regression problems based on aspects that quantify the linearity of the data, 
                the presence of informative feature, the sparsity and dimensionality of the datasets.
""")

st.subheader("Data")
st.write("""These measurements indicate the computational demands of each algorithm, 
                    as they indicate the time taken and the size occupied.
                    They also indicate the size of the resulting vector, previously chosen.
""")

st.subheader("Measures of network")
st.write("""
        The network measures represent the dataset as a graph and extract structural information from it.
        1. **Density**: Average Density of the network (Density) represents the number of edges in the graph, 
                divided by the maximum number of edges between pairs of data points;
        2. **Clustering Coefficient**: averages the clustering tendency of the vertexes 
                by the ratio of existent edges between its neighbors and the total number of edges that could possibly exist between them;
""")

st.subheader("Measures of class balance")
st.write("""
        These measures capture the differences in the number of examples per class in the dataset. 
        When these differences are severe, problems related to generalization of the ML classification techniques could happen 
        because of the imbalance ratio.
        1. **C1**: The entropy of class proportions (C1) capture the imbalance in a dataset based on the proportions of examples per class;
        2. **C2**: The imbalance ratio (C2) is an index computed for measuring class balance. 
                This is a version of the measure that is also suited for multiclass classification problems;
""")

st.subheader("Measures of overlapping")
st.write('''
            The overlapping measures evaluate how informative the available features are to separate the classes. 
            If there is at least one very discriminative feature in the dataset, 
            the problem can be considered simpler than if there is no such an attribute.
            
            1. **F1**: Maximum Fisher’s Discriminant Ratio (F1) measures the overlap between the values of the features 
                and takes the value of the largest discriminant ratio among all the available features.
            2. **F1v**: Directional-vector maximum Fisher’s discriminant ratio (F1v) complements F1 by searching for a vector able to separate two classes after the training examples have been projected into it.
            3. **F2**: Volume of the overlapping region (F2) computes the overlap of the distributions of the fea- tures values within the classes. 
                F2 can be determined by finding, for each feature its minimum and maximum values in the classes.
            4. **F3**: The maximum individual feature efficiency (F3) of each feature is given by the ratio between the number of examples that are not in the overlapping region of two classes and the total number of examples. 
                This measure returns the maximum of the values found among the input features.
            5. **F4**: Collective feature efficiency (F4) get an overview on how various features may work together in data separation. 
                First the most discriminative feature according to F3 is selected and all examples that can be separated by this feature are removed from the dataset. The previous step is repeated on the remaining dataset until all the features have been considered or no example remains. F4 returns the ratio of examples that have been discriminated.

''')

st.subheader("Measures of linearity")
st.write('''
            The linearity measures try to quantify if it is possible to separate the labels by a hyperplane or linear function. 
            The underlying assumption is that a linearly separable problem can be considered simpler than a problem requiring a non-linear decision boundary.
''')

st.subheader("Measures of neighborhood")
st.write('''
            The Neighborhood measures analyze the neighborhoods of the data items and try to capture class overlapping and the shape of the decision boundary. 
            They work over a distance matrix storing the distances between all pairs of data points in the dataset.

            1. **N1**: Fraction of borderline points (N1) computes the percentage of vertexes incident to edges connecting examples of opposite classes in a Minimum Spanning Tree (MST).
            2. **N2**: Ratio of intra/extra class nearest neighbor distance (N2) computes the ratio of two sums: intra-class and inter-class. 
                The former corresponds to the sum of the distances between each example and its closest neighbor from the same class. 
                The later is the sum of the distances between each example and its closest neighbor from another class (nearest enemy).
            3. **N3**: Error rate of the nearest neighbor (N3) classifier corresponds to the error rate of a one Nearest Neighbor (1NN) classifier, 
                estimated using a leave-one-out procedure in dataset.
            4. **LSC**: Local Set Average Cardinality (LSC) is based on Local Set (LS) and defined as the set of points 
                from the dataset whose distance of each example is smaller than the distance from the exemples of the different class. 
                LSC is the average of the LS.
''')

st.subheader("Measures of dimensionality")
st.write('''
    These measures give an indicative of data sparsity. 
    They capture how sparse a datasets tend to have regions of low density. 
    These regions are know to be more difficult to extract good classification and regression models.
    1. **T2**: Average number of points per dimension (T2) is given by the ratio between the number of examples and dimensionality of the dataset.
    2. **T3**: Average number of points per PCA (T3) is similar to T2, 
        but uses the number of PCA com- ponents needed to represent 95 variability as the base of data sparsity assessment.
    3. **T4**: Ratio of the PCA Dimension to the Original (T4) estimates the proportion of relevant and the original dimensions for a dataset.
''')

